{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d66ee291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO \n",
    "import os,sys\n",
    "import warnings   \n",
    "warnings.filterwarnings('ignore')\n",
    "import configparser\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import argparse\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e83f94c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def revComp(seq):\n",
    "    complementSeq=seq.translate(str.maketrans('ACGTacgtRYMKrymkVBHDvbhd', 'TGCAtgcaYRKMyrkmBVDHbvdh'))\n",
    "    revcompSeq = complementSeq[::-1]\n",
    "    return revcompSeq\n",
    "\n",
    "\n",
    "def conf_read(filename): \n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(filename)\n",
    "    res = dict(config._sections[\"point\"])\n",
    "    return res\n",
    "\n",
    "def blast_search(input_file_path,genome,workdir):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        input_file_path[str]:  input information\n",
    "        genome[str]:  edit reference\n",
    "        workdir[str]: dir path\n",
    "    Return[dict]\n",
    "        {\n",
    "            \"key1\":{\n",
    "                \"chrom\":\"NC_001133.9\",\n",
    "                \"start\":\"1000\",\n",
    "                \"unique_mapped\":1,  100% comparison\n",
    "                \"mapped\":1,  frequency\n",
    "                \"reverse_mapped\":1, frequency\n",
    "                \"description\":\"NC_001133.9:26529-26708;NC_001133.9:26664-26843;\",  \n",
    "            },\n",
    "        }\n",
    "\n",
    "    \"\"\"\n",
    "    blast_output_file_path=os.path.join(workdir,'blast_search.txt')\n",
    "    ref_lib=genome.split('/')[-1].split('.')[0]\n",
    "    input_fasta = os.path.join(workdir,'blast.fasta')\n",
    "    fasta_length_dict = {}\n",
    "    my_records = []\n",
    "    with open(input_file_path,'r') as ifile:\n",
    "        index = 0 \n",
    "        for line in ifile:\n",
    "            if index != 0 :\n",
    "                linelist = line.split(',')\n",
    "                seqid = linelist[0]\n",
    "                seq = linelist[1].strip()\n",
    "                rec = SeqRecord(Seq(seq),id=seqid)\n",
    "\n",
    "                fasta_length_dict[seqid] = len(seq)\n",
    "                my_records.append(rec)\n",
    "            index += 1\n",
    "    # input fasta\n",
    "    SeqIO.write(my_records, input_fasta, \"fasta\")\n",
    "    # run blast\n",
    "    os.system(\"makeblastdb -in \"+genome+\" -dbtype nucl -parse_seqids -out \"+ref_lib)\n",
    "    os.system(\"blastn -query \"+input_fasta+\" -db \"+ref_lib+\" -outfmt 6 -task blastn -out \"+blast_output_file_path+\" -evalue 1e-30 \")\n",
    "\n",
    "    # return\n",
    "    dictall = {}\n",
    "    with open(blast_output_file_path,\"r\") as f:\n",
    "        for i in f:\n",
    "            linelist = i.split('\\t')\n",
    "            key = linelist[0]\n",
    "            chrom = linelist[1]\n",
    "            identity = linelist[2]\n",
    "            allength = linelist[3]\n",
    "            start = linelist[8]\n",
    "            end = linelist[9]\n",
    "            \n",
    "            if key not in dictall:\n",
    "                dictall[key] = {\n",
    "                    \"chrom\":chrom,\n",
    "                    \"start\":start,\n",
    "                    \"unique_mapped\":1 if (int(float(identity)) == 100 and int(float(allength))==fasta_length_dict[key]) else 0,\n",
    "                    \"mapped\":1,\n",
    "                    \"reverse_mapped\":1 if (int(start) > int(end) and int(float(identity)) == 100 and int(float(allength))==fasta_length_dict[key]) else 0,\n",
    "                    \"description\":'%s:%s-%s;' %(chrom,start,end),\n",
    "                }\n",
    "            else:\n",
    "                dictall[key][\"mapped\"] += 1\n",
    "                if int(float(identity)) == 100 and int(float(allength))==fasta_length_dict[key] :\n",
    "                    dictall[key][\"unique_mapped\"] += 1\n",
    "                    dictall[key][\"chrom\"] = chrom\n",
    "                    dictall[key][\"start\"] = start\n",
    "                    if int(start) > int(end):\n",
    "                        dictall[key][\"reverse_mapped\"] += 1\n",
    "                    dictall[key][\"description\"] += '%s:%s-%s;' %(chrom,start,end)\n",
    "    return dictall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ddfb3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_to_primer_template(input_file_path, genome,workdir):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        input_file_path[str]:  input information\n",
    "        genome[str]:  edit reference\n",
    "        config[dic]: points information\n",
    "    Return [dict]\n",
    "        {\n",
    "            \"key1\":{\n",
    "                \"seq_uha_max_whole\":\"\",\n",
    "                \"seq_dha_max_whole\":\"\",\n",
    "                \"seq_altered\":\"\",\n",
    "                \"type\":\"\",   # [substitution,deletion,insertion]\n",
    "                \"ref\":\"\",\n",
    "                \"uha_upstream\": seq_uha_max_whole  up 100bp  sequence,\n",
    "                \"dha_downstream\":seq_dha_max_whole  down 100bp sequence,\n",
    "            },\n",
    "            \"key2\":{\n",
    "                \"seq_uha_max_whole\":\"\",\n",
    "                \"seq_dha_max_whole\":\"\",\n",
    "                \"seq_altered\":\"\",\n",
    "                \"type\":\"\",\n",
    "                \"ref\":\"\",\n",
    "                \"uha_upstream\": seq_uha_max_whole  up 100bp  sequence,\n",
    "                \"dha_downstream\":seq_dha_max_whole  down 100bp sequence,\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    "    input_format=input_file_path.split('.')[-1]\n",
    "    with open(input_file_path,'r') as f:\n",
    "        input_header = f.readlines()[0]\n",
    "        # print(input_header)\n",
    "\n",
    "    primer_template = {}\n",
    "\n",
    "    # blast error file\n",
    "    with open(os.path.join(workdir,'error.txt'),'w') as blast_error_handler:\n",
    "        blast_error_handler.write('ID\\tERROR\\n')\n",
    "        if input_format != 'csv':\n",
    "            error_message = \"The input file format needs to be 'csv'\"\n",
    "            print(error_message)\n",
    "            return error_message\n",
    "        elif 'Sequence upstream' in input_header:\n",
    "            # input type 1: upstream\n",
    "            print('processing upstream input file ...')\n",
    "            record_dict = SeqIO.to_dict(SeqIO.parse(genome, \"fasta\"))\n",
    "            blast_search_dict = blast_search(input_file_path,genome,workdir)\n",
    "            df=pd.read_csv(input_file_path)\n",
    "\n",
    "            num_lines_df=df.shape[0]\n",
    "            for i in range(num_lines_df):\n",
    "                data=df.loc[i].values\n",
    "                #print(data)\n",
    "                mun_id=str(data[0])\n",
    "                if len(data) < 5:\n",
    "                    error_message = \"Some necessary input information is missing in the line \"+mun_id+\" of the input file\"\n",
    "                    print(error_message)\n",
    "                    return  error_message\n",
    "                else:\n",
    "                    upstream = data[1].strip().upper()\n",
    "                    ref = data[2]\n",
    "                    alt = data[3]\n",
    "                    mutation_type = data[4].strip().lower()\n",
    "                    name = mun_id\n",
    "                    \n",
    "                    if mun_id not in blast_search_dict:\n",
    "                        # no blast\n",
    "                        error_message = \"The upstream sequence of \" + mun_id + \" can not be mapped to the target genome. please check whether the target sequence is located on the target genome.\"\n",
    "                        blast_error_handler.write(mun_id + '\\t' +  error_message+ '\\n')\n",
    "                    elif blast_search_dict[mun_id][\"unique_mapped\"] > 1:\n",
    "                        # Compare 100 times\n",
    "                        error_message = \"The upstream sequence of \" + mun_id + \"  can be mapped to multiple loci in the target genome, %s, Please provide a longer upstream seqeunce.\" % blast_search_dict[mun_id][\"description\"]\n",
    "                        blast_error_handler.write(mun_id+'\\t'+ error_message+'\\n')\n",
    "                    elif blast_search_dict[mun_id][\"unique_mapped\"] == 0:\n",
    "                        # No 100 comparison\n",
    "\n",
    "                        error_message = \"The upstream sequence of \" + mun_id + \" can not be uniquely mapped to the target genome. Please check whether the target sequence is located on the target genome.\"\n",
    "                        blast_error_handler.write(mun_id+'\\t'+error_message+'\\n')\n",
    "                    elif blast_search_dict[mun_id][\"unique_mapped\"] == 1:\n",
    "                        # Index of the base starting to mutate on gene\n",
    "                        if blast_search_dict[mun_id][\"reverse_mapped\"]:\n",
    "                            record = revComp(str(record_dict[blast_search_dict[mun_id][\"chrom\"]].seq))\n",
    "                            upstream_start_index = len(record) - int(blast_search_dict[mun_id][\"start\"])\n",
    "                            strand = \"-\"  \n",
    "                        else:\n",
    "                            record = str(record_dict[blast_search_dict[mun_id][\"chrom\"]].seq)\n",
    "                            upstream_start_index = int(blast_search_dict[mun_id][\"start\"])-1\n",
    "                            strand = \"+\"\n",
    "                        chrom = blast_search_dict[mun_id][\"chrom\"]\n",
    "                        mutation_pos_index = upstream_start_index + len(upstream)\n",
    "                        \n",
    "                        res = create_mutation_info(\n",
    "                            record,mutation_type,mutation_pos_index,\n",
    "                            ref,alt,strand,chrom,\n",
    "                            name,mun_id\n",
    "                            )\n",
    "                        \n",
    "                        if isinstance(res,str):\n",
    "                            blast_error_handler.write(mun_id+'\\t'+res+'\\n')\n",
    "                        else:\n",
    "                            primer_template[mun_id] = res\n",
    "\n",
    "\n",
    "        elif 'Chr,Pos,Strand' in input_header:\n",
    "            # input type 2: vcf\n",
    "            print('processing vcf input file ...')\n",
    "            record_dict = SeqIO.to_dict(SeqIO.parse(genome, \"fasta\"))\n",
    "            df=pd.read_csv(input_file_path)\n",
    "            num_lines_df=df.shape[0]\n",
    "            for i in range(num_lines_df):\n",
    "                data=df.loc[i].values\n",
    "                #print(data)\n",
    "                mun_id=str(data[0])\n",
    "                if len(data) < 7:\n",
    "                    error_message = \"Some necessary input information is missing in the line \"+mun_id+\" of the input file\"\n",
    "                    print(error_message)\n",
    "                    return  error_message\n",
    "                else:\n",
    "                    chrom = data[1].strip()\n",
    "                    pos = data[2]\n",
    "                    strand = data[3]\n",
    "                    ref = data[4].strip()\n",
    "                    alt = data[5]\n",
    "                    mutation_type = data[6]\n",
    "                    name = mun_id\n",
    "\n",
    "                    if strand == '+':\n",
    "                        record = str(record_dict[chrom].seq)\n",
    "                        mutation_pos_index = int(pos) - 1\n",
    "                    elif strand == '-':\n",
    "                        record = revComp(str(record_dict[chrom].seq))\n",
    "                        mutation_pos_index = len(record) - int(pos)\n",
    "                        \n",
    "                    # get mutation info dict\n",
    "                    res = create_mutation_info(\n",
    "                        record,mutation_type,mutation_pos_index,\n",
    "                        ref,alt,strand,chrom,\n",
    "                        name,mun_id\n",
    "                        )\n",
    "\n",
    "                    if isinstance(res,str):\n",
    "                        blast_error_handler.write(mun_id + '\\t'+ res +'\\n')\n",
    "                    else:\n",
    "                        primer_template[mun_id] = res\n",
    "        else:\n",
    "            error_message = \"The input file format not supported, Please rightly prepare input file for target manipulation as the example of 2,3-BD.\"\n",
    "            return  error_message\n",
    "    return primer_template\n",
    "\n",
    "\n",
    "def dict_to_df(dict_input_seq):\n",
    "    info_input_df = pd.DataFrame()\n",
    "    for item in dict_input_seq:\n",
    "        df = pd.DataFrame([dict_input_seq[item]])\n",
    "        df.insert(loc=0,value=item,column='id')\n",
    "        info_input_df = info_input_df.append(df)\n",
    "    info_input_df = info_input_df.reset_index(drop=True)\n",
    "    return info_input_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52b6ef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path='./input/editor_info.csv'\n",
    "genome_path='./input/GCA_000011325.1_ASM1132v1_genomic.fna'\n",
    "convert_input_file_chopchopInput_workdir =\"./output/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3378e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing upstream input file ...\n",
      "\n",
      "\n",
      "Building a new DB, current time: 03/03/2023 05:45:27\n",
      "New DB name:   /home/yanghe/program/data_preprocessing/GCA_000011325\n",
      "New DB title:  ./input/GCA_000011325.1_ASM1132v1_genomic.fna\n",
      "Sequence type: Nucleotide\n",
      "Deleted existing Nucleotide BLAST database named /home/yanghe/program/data_preprocessing/GCA_000011325\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 1 sequences in 0.0530791 seconds.\n"
     ]
    }
   ],
   "source": [
    "dict_input_seq = input_to_primer_template(input_file_path,genome_path,convert_input_file_chopchopInput_workdir)\n",
    "info_input_df = dict_to_df(dict_input_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3c54b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>seq_altered</th>\n",
       "      <th>type</th>\n",
       "      <th>ref</th>\n",
       "      <th>strand</th>\n",
       "      <th>mutation_pos_index</th>\n",
       "      <th>geneid</th>\n",
       "      <th>name</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cgl0006_1176_G_A_sub</td>\n",
       "      <td>A</td>\n",
       "      <td>substitution</td>\n",
       "      <td>G</td>\n",
       "      <td>plus</td>\n",
       "      <td>6529</td>\n",
       "      <td>BA000036.3</td>\n",
       "      <td>Cgl0006_1176_G_A_sub</td>\n",
       "      <td>BA000036.3:6529-6530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cgl1436_1113_CAA_del</td>\n",
       "      <td></td>\n",
       "      <td>deletion</td>\n",
       "      <td>CAA</td>\n",
       "      <td>plus</td>\n",
       "      <td>1514089</td>\n",
       "      <td>BA000036.3</td>\n",
       "      <td>Cgl1436_1113_CAA_del</td>\n",
       "      <td>BA000036.3:1514089-1514092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cgl2342_213_GCA_ins</td>\n",
       "      <td>GCA</td>\n",
       "      <td>insertion</td>\n",
       "      <td>-</td>\n",
       "      <td>plus</td>\n",
       "      <td>2484874</td>\n",
       "      <td>BA000036.3</td>\n",
       "      <td>Cgl2342_213_GCA_ins</td>\n",
       "      <td>BA000036.3:2484874-2484875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cgl1790_1647_TCC_sub</td>\n",
       "      <td>TTA</td>\n",
       "      <td>substitution</td>\n",
       "      <td>GAC</td>\n",
       "      <td>plus</td>\n",
       "      <td>1899017</td>\n",
       "      <td>BA000036.3</td>\n",
       "      <td>Cgl1790_1647_TCC_sub</td>\n",
       "      <td>BA000036.3:1899017-1899020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cgl1386_327_18to15_sub</td>\n",
       "      <td>GCGTGGCGCGGTTAA</td>\n",
       "      <td>substitution</td>\n",
       "      <td>gctgagatcgaaaagcgt</td>\n",
       "      <td>plus</td>\n",
       "      <td>1454441</td>\n",
       "      <td>BA000036.3</td>\n",
       "      <td>Cgl1386_327_18to15_sub</td>\n",
       "      <td>BA000036.3:1454441-1454459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cgl0591_-1_Ppgk_promoter_ins</td>\n",
       "      <td>TTAATCAATACAATTGAATACCGGTGCCAGCGCCACACAATGTGTA...</td>\n",
       "      <td>insertion</td>\n",
       "      <td>-</td>\n",
       "      <td>plus</td>\n",
       "      <td>604469</td>\n",
       "      <td>BA000036.3</td>\n",
       "      <td>Cgl0591_-1_Ppgk_promoter_ins</td>\n",
       "      <td>BA000036.3:604469-604470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cgl0141_cds_del</td>\n",
       "      <td></td>\n",
       "      <td>deletion</td>\n",
       "      <td>CTACATGCGATTCTTGGTGCGCGCAGTGGCAGGAGCGGTCCATGGA...</td>\n",
       "      <td>plus</td>\n",
       "      <td>153222</td>\n",
       "      <td>BA000036.3</td>\n",
       "      <td>Cgl0141_cds_del</td>\n",
       "      <td>BA000036.3:153222-155613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>153019_ecoil_ybeL_ins</td>\n",
       "      <td>ATGAACAAGGTTGCTCAATATTACCGTGAACTGGTTGCGTCACTGA...</td>\n",
       "      <td>insertion</td>\n",
       "      <td>-</td>\n",
       "      <td>plus</td>\n",
       "      <td>153019</td>\n",
       "      <td>BA000036.3</td>\n",
       "      <td>153019_ecoil_ybeL_ins</td>\n",
       "      <td>BA000036.3:153019-153020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cgl0851_ecoli_pgi_sub</td>\n",
       "      <td>atgaaaaacatcaatccaacgcagaccgctgcctggcaggcactac...</td>\n",
       "      <td>substitution</td>\n",
       "      <td>ctacctatttgcgcggtaccacttaatcagtgaatcagtggaagaa...</td>\n",
       "      <td>plus</td>\n",
       "      <td>907755</td>\n",
       "      <td>BA000036.3</td>\n",
       "      <td>Cgl0851_ecoli_pgi_sub</td>\n",
       "      <td>BA000036.3:907755-909378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id  \\\n",
       "0          Cgl0006_1176_G_A_sub   \n",
       "1          Cgl1436_1113_CAA_del   \n",
       "2           Cgl2342_213_GCA_ins   \n",
       "3          Cgl1790_1647_TCC_sub   \n",
       "4        Cgl1386_327_18to15_sub   \n",
       "5  Cgl0591_-1_Ppgk_promoter_ins   \n",
       "6               Cgl0141_cds_del   \n",
       "7         153019_ecoil_ybeL_ins   \n",
       "8         Cgl0851_ecoli_pgi_sub   \n",
       "\n",
       "                                         seq_altered          type  \\\n",
       "0                                                  A  substitution   \n",
       "1                                                         deletion   \n",
       "2                                                GCA     insertion   \n",
       "3                                                TTA  substitution   \n",
       "4                                    GCGTGGCGCGGTTAA  substitution   \n",
       "5  TTAATCAATACAATTGAATACCGGTGCCAGCGCCACACAATGTGTA...     insertion   \n",
       "6                                                         deletion   \n",
       "7  ATGAACAAGGTTGCTCAATATTACCGTGAACTGGTTGCGTCACTGA...     insertion   \n",
       "8  atgaaaaacatcaatccaacgcagaccgctgcctggcaggcactac...  substitution   \n",
       "\n",
       "                                                 ref strand  \\\n",
       "0                                                  G   plus   \n",
       "1                                                CAA   plus   \n",
       "2                                                  -   plus   \n",
       "3                                                GAC   plus   \n",
       "4                                 gctgagatcgaaaagcgt   plus   \n",
       "5                                                  -   plus   \n",
       "6  CTACATGCGATTCTTGGTGCGCGCAGTGGCAGGAGCGGTCCATGGA...   plus   \n",
       "7                                                  -   plus   \n",
       "8  ctacctatttgcgcggtaccacttaatcagtgaatcagtggaagaa...   plus   \n",
       "\n",
       "   mutation_pos_index      geneid                          name  \\\n",
       "0                6529  BA000036.3          Cgl0006_1176_G_A_sub   \n",
       "1             1514089  BA000036.3          Cgl1436_1113_CAA_del   \n",
       "2             2484874  BA000036.3           Cgl2342_213_GCA_ins   \n",
       "3             1899017  BA000036.3          Cgl1790_1647_TCC_sub   \n",
       "4             1454441  BA000036.3        Cgl1386_327_18to15_sub   \n",
       "5              604469  BA000036.3  Cgl0591_-1_Ppgk_promoter_ins   \n",
       "6              153222  BA000036.3               Cgl0141_cds_del   \n",
       "7              153019  BA000036.3         153019_ecoil_ybeL_ins   \n",
       "8              907755  BA000036.3         Cgl0851_ecoli_pgi_sub   \n",
       "\n",
       "                       region  \n",
       "0        BA000036.3:6529-6530  \n",
       "1  BA000036.3:1514089-1514092  \n",
       "2  BA000036.3:2484874-2484875  \n",
       "3  BA000036.3:1899017-1899020  \n",
       "4  BA000036.3:1454441-1454459  \n",
       "5    BA000036.3:604469-604470  \n",
       "6    BA000036.3:153222-155613  \n",
       "7    BA000036.3:153019-153020  \n",
       "8    BA000036.3:907755-909378  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29179460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9481998d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc47c8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"uha_dha_config\": {\n",
    "        \"max_right_arm_seq_length\": 1050,\n",
    "        \"max_left_arm_seq_length\": 1050,\n",
    "        \"min_left_arm_seq_length\": 1000,\n",
    "        \"min_right_arm_seq_length\": 1000\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e40535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7a0c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df99ff54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9037e979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b681f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "637e8812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc45b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37513d34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e002c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d1b3d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d338a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cc6c69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ebe7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deba6569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31f7492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0877f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d36a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO \n",
    "import os,sys\n",
    "import warnings   \n",
    "warnings.filterwarnings('ignore')\n",
    "import configparser\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "\n",
    "def revComp(seq):\n",
    "    complementSeq=seq.translate(str.maketrans('ACGTacgtRYMKrymkVBHDvbhd', 'TGCAtgcaYRKMyrkmBVDHbvdh'))\n",
    "    revcompSeq = complementSeq[::-1]\n",
    "    return revcompSeq\n",
    "\n",
    "\n",
    "def conf_read(filename): \n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(filename)\n",
    "    res = dict(config._sections[\"point\"])\n",
    "    return res\n",
    "\n",
    "def input_to_primer_template(input_file_path, genome,config,workdir):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        input_file_path[str]:  input information\n",
    "        genome[str]:  edit reference\n",
    "        config[dic]: points information\n",
    "    Return [dict]\n",
    "        {\n",
    "            \"key1\":{\n",
    "                \"seq_uha_max_whole\":\"\",\n",
    "                \"seq_dha_max_whole\":\"\",\n",
    "                \"seq_altered\":\"\",\n",
    "                \"type\":\"\",   # [substitution,deletion,insertion]\n",
    "                \"ref\":\"\",\n",
    "                \"uha_upstream\": seq_uha_max_whole  up 100bp  sequence,\n",
    "                \"dha_downstream\":seq_dha_max_whole  down 100bp sequence,\n",
    "            },\n",
    "            \"key2\":{\n",
    "                \"seq_uha_max_whole\":\"\",\n",
    "                \"seq_dha_max_whole\":\"\",\n",
    "                \"seq_altered\":\"\",\n",
    "                \"type\":\"\",\n",
    "                \"ref\":\"\",\n",
    "                \"uha_upstream\": seq_uha_max_whole  up 100bp  sequence,\n",
    "                \"dha_downstream\":seq_dha_max_whole  down 100bp sequence,\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    "    input_format=input_file_path.split('.')[-1]\n",
    "    with open(input_file_path,'r') as f:\n",
    "        input_header = f.readlines()[0]\n",
    "        # print(input_header)\n",
    "\n",
    "    primer_template = {}\n",
    "\n",
    "    # blast error file\n",
    "    with open(os.path.join(workdir,'error.txt'),'w') as blast_error_handler:\n",
    "        blast_error_handler.write('ID\\tERROR\\n')\n",
    "        if input_format != 'csv':\n",
    "            error_message = \"The input file format needs to be 'csv'\"\n",
    "            print(error_message)\n",
    "            return error_message\n",
    "        elif 'Sequence upstream' in input_header:\n",
    "            # input type 1: upstream\n",
    "            print('processing upstream input file ...')\n",
    "            record_dict = SeqIO.to_dict(SeqIO.parse(genome, \"fasta\"))\n",
    "            blast_search_dict = blast_search(input_file_path,genome,workdir)\n",
    "            df=pd.read_csv(input_file_path)\n",
    "\n",
    "            num_lines_df=df.shape[0]\n",
    "            for i in range(num_lines_df):\n",
    "                data=df.loc[i].values\n",
    "                #print(data)\n",
    "                mun_id=str(data[0])\n",
    "                if len(data) < 5:\n",
    "                    error_message = \"Some necessary input information is missing in the line \"+mun_id+\" of the input file\"\n",
    "                    print(error_message)\n",
    "                    return  error_message\n",
    "                else:\n",
    "                    upstream = data[1].strip().upper()\n",
    "                    ref = data[2]\n",
    "                    alt = data[3]\n",
    "                    mutation_type = data[4].strip().lower()\n",
    "                    name = mun_id\n",
    "                    \n",
    "                    if mun_id not in blast_search_dict:\n",
    "                        # no blast\n",
    "                        error_message = \"The upstream sequence of \" + mun_id + \" can not be mapped to the target genome. please check whether the target sequence is located on the target genome.\"\n",
    "                        blast_error_handler.write(mun_id + '\\t' +  error_message+ '\\n')\n",
    "                    elif blast_search_dict[mun_id][\"unique_mapped\"] > 1:\n",
    "                        # Compare 100 times\n",
    "                        error_message = \"The upstream sequence of \" + mun_id + \"  can be mapped to multiple loci in the target genome, %s, Please provide a longer upstream seqeunce.\" % blast_search_dict[mun_id][\"description\"]\n",
    "                        blast_error_handler.write(mun_id+'\\t'+ error_message+'\\n')\n",
    "                    elif blast_search_dict[mun_id][\"unique_mapped\"] == 0:\n",
    "                        # No 100 comparison\n",
    "\n",
    "                        error_message = \"The upstream sequence of \" + mun_id + \" can not be uniquely mapped to the target genome. Please check whether the target sequence is located on the target genome.\"\n",
    "                        blast_error_handler.write(mun_id+'\\t'+error_message+'\\n')\n",
    "                    elif blast_search_dict[mun_id][\"unique_mapped\"] == 1:\n",
    "                        # Index of the base starting to mutate on gene\n",
    "                        if blast_search_dict[mun_id][\"reverse_mapped\"]:\n",
    "                            record = revComp(str(record_dict[blast_search_dict[mun_id][\"chrom\"]].seq))\n",
    "                            upstream_start_index = len(record) - int(blast_search_dict[mun_id][\"start\"])\n",
    "                            strand = \"-\"  \n",
    "                        else:\n",
    "                            record = str(record_dict[blast_search_dict[mun_id][\"chrom\"]].seq)\n",
    "                            upstream_start_index = int(blast_search_dict[mun_id][\"start\"])-1\n",
    "                            strand = \"+\"\n",
    "                        chrom = blast_search_dict[mun_id][\"chrom\"]\n",
    "                        mutation_pos_index = upstream_start_index + len(upstream)\n",
    "\n",
    "\n",
    "                        # get mutation info dict\n",
    "                        res = create_mutation_info(\n",
    "                            record,mutation_type,mutation_pos_index,\n",
    "                            ref,alt,strand,chrom,\n",
    "                            name,mun_id,config\n",
    "                            )\n",
    "\n",
    "                            \n",
    "                        if isinstance(res,str):\n",
    "                            blast_error_handler.write(mun_id+'\\t'+res+'\\n')\n",
    "                        else:\n",
    "                            primer_template[mun_id] = res\n",
    "\n",
    "\n",
    "        elif 'Chr,Pos,Strand' in input_header:\n",
    "            # input type 2: vcf\n",
    "            print('processing vcf input file ...')\n",
    "            record_dict = SeqIO.to_dict(SeqIO.parse(genome, \"fasta\"))\n",
    "            df=pd.read_csv(input_file_path)\n",
    "            num_lines_df=df.shape[0]\n",
    "            for i in range(num_lines_df):\n",
    "                data=df.loc[i].values\n",
    "                #print(data)\n",
    "                mun_id=str(data[0])\n",
    "                if len(data) < 7:\n",
    "                    error_message = \"Some necessary input information is missing in the line \"+mun_id+\" of the input file\"\n",
    "                    print(error_message)\n",
    "                    return  error_message\n",
    "                else:\n",
    "                    chrom = data[1].strip()\n",
    "                    pos = data[2]\n",
    "                    strand = data[3]\n",
    "                    ref = data[4].strip()\n",
    "                    alt = data[5]\n",
    "                    mutation_type = data[6]\n",
    "                    name = mun_id\n",
    "\n",
    "                    if strand == '+':\n",
    "                        record = str(record_dict[chrom].seq)\n",
    "                        mutation_pos_index = int(pos) - 1\n",
    "                    elif strand == '-':\n",
    "                        record = revComp(str(record_dict[chrom].seq))\n",
    "                        mutation_pos_index = len(record) - int(pos)\n",
    "                    # get mutation info dict\n",
    "                    res = create_mutation_info(\n",
    "                        record,mutation_type,mutation_pos_index,\n",
    "                        ref,alt,strand,chrom,\n",
    "                        name,mun_id,config\n",
    "                        )\n",
    "                    if isinstance(res,str):\n",
    "                        blast_error_handler.write(mun_id + '\\t'+ res +'\\n')\n",
    "                    else:\n",
    "                        primer_template[mun_id] = res\n",
    "        else:\n",
    "            error_message = \"The input file format not supported, Please rightly prepare input file for target manipulation as the example of 2,3-BD.\"\n",
    "            return  error_message\n",
    "    return primer_template\n",
    "\n",
    "\n",
    "def blast_search(input_file_path,genome,workdir):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        input_file_path[str]:  input information\n",
    "        genome[str]:  edit reference\n",
    "        workdir[str]: dir path\n",
    "    Return[dict]\n",
    "        {\n",
    "            \"key1\":{\n",
    "                \"chrom\":\"NC_001133.9\",\n",
    "                \"start\":\"1000\",\n",
    "                \"unique_mapped\":1,  100% comparison\n",
    "                \"mapped\":1,  frequency\n",
    "                \"reverse_mapped\":1, frequency\n",
    "                \"description\":\"NC_001133.9:26529-26708;NC_001133.9:26664-26843;\",  \n",
    "            },\n",
    "        }\n",
    "\n",
    "    \"\"\"\n",
    "    blast_output_file_path=os.path.join(workdir,'blast_search.txt')\n",
    "    ref_lib=genome.split('/')[-1].split('.')[0]\n",
    "    input_fasta = os.path.join(workdir,'blast.fasta')\n",
    "    fasta_length_dict = {}\n",
    "    my_records = []\n",
    "    with open(input_file_path,'r') as ifile:\n",
    "        index = 0 \n",
    "        for line in ifile:\n",
    "            if index != 0 :\n",
    "                linelist = line.split(',')\n",
    "                seqid = linelist[0]\n",
    "                seq = linelist[1].strip()\n",
    "                rec = SeqRecord(Seq(seq),id=seqid)\n",
    "\n",
    "                fasta_length_dict[seqid] = len(seq)\n",
    "                my_records.append(rec)\n",
    "            index += 1\n",
    "    # input fasta\n",
    "    SeqIO.write(my_records, input_fasta, \"fasta\")\n",
    "    # run blast\n",
    "    os.system(\"makeblastdb -in \"+genome+\" -dbtype nucl -parse_seqids -out \"+ref_lib)\n",
    "    os.system(\"blastn -query \"+input_fasta+\" -db \"+ref_lib+\" -outfmt 6 -task blastn -out \"+blast_output_file_path+\" -evalue 1e-30 \")\n",
    "\n",
    "    # return\n",
    "    dictall = {}\n",
    "    with open(blast_output_file_path,\"r\") as f:\n",
    "        for i in f:\n",
    "            linelist = i.split('\\t')\n",
    "            key = linelist[0]\n",
    "            chrom = linelist[1]\n",
    "            identity = linelist[2]\n",
    "            allength = linelist[3]\n",
    "            start = linelist[8]\n",
    "            end = linelist[9]\n",
    "            \n",
    "            if key not in dictall:\n",
    "                dictall[key] = {\n",
    "                    \"chrom\":chrom,\n",
    "                    \"start\":start,\n",
    "                    \"unique_mapped\":1 if (int(float(identity)) == 100 and int(float(allength))==fasta_length_dict[key]) else 0,\n",
    "                    \"mapped\":1,\n",
    "                    \"reverse_mapped\":1 if (int(start) > int(end) and int(float(identity)) == 100 and int(float(allength))==fasta_length_dict[key]) else 0,\n",
    "                    \"description\":'%s:%s-%s;' %(chrom,start,end),\n",
    "                }\n",
    "            else:\n",
    "                dictall[key][\"mapped\"] += 1\n",
    "                if int(float(identity)) == 100 and int(float(allength))==fasta_length_dict[key] :\n",
    "                    dictall[key][\"unique_mapped\"] += 1\n",
    "                    dictall[key][\"chrom\"] = chrom\n",
    "                    dictall[key][\"start\"] = start\n",
    "                    if int(start) > int(end):\n",
    "                        dictall[key][\"reverse_mapped\"] += 1\n",
    "                    dictall[key][\"description\"] += '%s:%s-%s;' %(chrom,start,end)\n",
    "    return dictall\n",
    "\n",
    "\n",
    "def create_mutation_info(record,mutation_type,mutation_pos_index,ref,alt,strand,chrom,name,mun_id,config):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        record[str]: mutation site located genome\n",
    "        mutation_type[str]: deletion insertion substitution\n",
    "        mutation_pos_index[int]:  mutation_pos_index information\n",
    "        ref[str]:  mutation_pos_index ref\n",
    "        alt[str]: alter sequence\n",
    "        strand[str]:  + plus   - minus\n",
    "        chrom[str]:  mutation site located genome name\n",
    "        name[str]: mutation name\n",
    "        mun_id[str]: mutation id\n",
    "        config[dict]:  information\n",
    "    Return [dict]\n",
    "        {\n",
    "            \"seq_uha_max_whole\":\"\",\n",
    "            \"seq_dha_max_whole\":\"\",\n",
    "            \"seq_altered\":\"\",\n",
    "            \"type\":\"\",   # [substitution,deletion,insertion]\n",
    "            \"ref\":\"\",\n",
    "            \"uha_upstream\": seq_uha_max_whole  up 100bp  sequence,\n",
    "            \"dha_downstream\":seq_dha_max_whole  down 100bp sequence,\n",
    "        }\n",
    "    \n",
    "    \"\"\"\n",
    "    max_left_arm_seq_length=int(config['max_left_arm_seq_length'])\n",
    "    max_right_arm_seq_length=int(config['max_right_arm_seq_length'])\n",
    "\n",
    "    # length \n",
    "    if mutation_pos_index - max_left_arm_seq_length < 0:\n",
    "        error_message = \"The length of upstream sequence of manipulation site of \" + mun_id + \" must be larger than sum of 'Max Length of UHA' and 'Max Length of UIS'.\"\n",
    "        return error_message\n",
    "    \n",
    "    if mutation_type ==  \"insertion\":\n",
    "        info_dict = {\n",
    "            \"seq_uha_max_whole\":str(record[\n",
    "                mutation_pos_index - max_left_arm_seq_length : mutation_pos_index\n",
    "            ]),\n",
    "            \"seq_dha_max_whole\":str(record[\n",
    "                mutation_pos_index : mutation_pos_index + max_right_arm_seq_length\n",
    "            ]),\n",
    "            \"seq_altered\":alt,\n",
    "            \"type\":mutation_type,\n",
    "            \"ref\":ref,\n",
    "            \"strand\":\"plus\" if strand ==\"+\" else \"minus\",\n",
    "            \"mutation_pos_index\":mutation_pos_index,\n",
    "            \"geneid\":chrom,\n",
    "            \"name\":name,\n",
    "            \"region\":chrom+ ':' +  str(mutation_pos_index) +'-'+ str(int(mutation_pos_index)+len(ref)),\n",
    "            \"uha_upstream\":str(  \n",
    "                record[\n",
    "                    mutation_pos_index - max_left_arm_seq_length - 100 : mutation_pos_index - max_left_arm_seq_length\n",
    "                ]\n",
    "            ),\n",
    "            \"dha_downstream\":str(\n",
    "                record[\n",
    "                    mutation_pos_index + max_right_arm_seq_length  : mutation_pos_index + max_right_arm_seq_length  + 100\n",
    "                ]\n",
    "            ),\n",
    "\n",
    "        }\n",
    "        return info_dict      \n",
    "\n",
    "#         return info_dict\n",
    "    if mutation_type in [\"deletion\",\"substitution\"]:\n",
    "        genome_ref = record[mutation_pos_index:mutation_pos_index+len(ref)]\n",
    "        # print(genome_ref)\n",
    "        if genome_ref.upper() == ref.upper():\n",
    "            info_dict = {\n",
    "                \"seq_uha_max_whole\":str(record[\n",
    "                    mutation_pos_index \n",
    "                    - max_left_arm_seq_length :mutation_pos_index\n",
    "                    ]),\n",
    "                \"seq_dha_max_whole\":str(record[\n",
    "                    mutation_pos_index + len(ref)\n",
    "                    : mutation_pos_index + len(ref) + max_right_arm_seq_length\n",
    "                    ]),\n",
    "                \"seq_altered\":\"\" if alt=='-' else alt,\n",
    "                \"type\":mutation_type,\n",
    "                \"ref\":ref,\n",
    "                \"strand\":\"plus\" if strand == \"+\" else \"minus\",\n",
    "                \"mutation_pos_index\":mutation_pos_index,\n",
    "                \"geneid\":chrom,\n",
    "                \"name\":name,   \n",
    "                \"region\": chrom+ ':' +  str(mutation_pos_index) +'-'+ str(int(mutation_pos_index)+len(ref)),\n",
    "                \"uha_upstream\":str(  \n",
    "                    record[\n",
    "                        mutation_pos_index \n",
    "                    - max_left_arm_seq_length - 100\n",
    "                    : mutation_pos_index \n",
    "                    - max_left_arm_seq_length\n",
    "\n",
    "                    ]),\n",
    "                \"dha_downstream\":str(\n",
    "                    record[\n",
    "                        mutation_pos_index + len(ref) + max_right_arm_seq_length\n",
    "                        : mutation_pos_index + len(ref) + max_right_arm_seq_length + 100\n",
    "                    ]),\n",
    "            }\n",
    "            return info_dict\n",
    "        else:\n",
    "            error_message = \"The target mutation ref of \" + mun_id + \" can not be found in reference, please check.\"\n",
    "            return error_message\n",
    "    else:\n",
    "        error_message = \"The target manipulation type of \" + mun_id + \" must be equal to 'insertion,substitution or deletion', Please rightly prepare input file for target manipulation as the example of 2,3-BD.\"\n",
    "        return  error_message\n",
    "\n",
    "\n",
    "\n",
    "def dict_to_df(dict_input_seq):\n",
    "    info_input_df = pd.DataFrame()\n",
    "    for item in dict_input_seq:\n",
    "        df = pd.DataFrame([dict_input_seq[item]])\n",
    "        df.insert(loc=0,value=item,column='id')\n",
    "        info_input_df = info_input_df.append(df)\n",
    "    info_input_df = info_input_df.reset_index(drop=True)\n",
    "    return info_input_df\n",
    "\n",
    "\n",
    "def execute_input_2_chopchop_input(input_file_path, uha_dha_config, genome_path, convert_input_file_chopchopInput_workdir, chopchop_input):\n",
    "    crispr_info = pd.read_csv(input_file_path)\n",
    "    config = uha_dha_config\n",
    "    dict_input_seq = input_to_primer_template(input_file_path,genome_path,config, convert_input_file_chopchopInput_workdir)\n",
    "    info_input_df = dict_to_df(dict_input_seq)\n",
    "    info_input_df.to_csv(chopchop_input)\n",
    "\n",
    "\n",
    "\n",
    "def main(data):\n",
    "\n",
    "    input_file_path = data['input_file_path']\n",
    "    uha_dha_config = data['uha_dha_config']\n",
    "    genome_path = data['ref_genome']\n",
    "    convert_input_file_chopchopInput_workdir = data['data_preprocessing_workdir']\n",
    "    \n",
    "    if not os.path.exists(convert_input_file_chopchopInput_workdir):\n",
    "        os.makedirs(convert_input_file_chopchopInput_workdir)\n",
    "    chopchop_input =os.path.join(\n",
    "        data['data_preprocessing_workdir'],\n",
    "        'info_input.csv'\n",
    "    )\n",
    "    \n",
    "    execute_input_2_chopchop_input(input_file_path, uha_dha_config, genome_path, convert_input_file_chopchopInput_workdir, chopchop_input)\n",
    "    return chopchop_input\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--input', '-i', help='input params file', required=True) \n",
    "    args = parser.parse_args()\n",
    "    input_path =  args.input\n",
    "    with open(input_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    main(data)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
